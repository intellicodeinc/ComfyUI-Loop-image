import torch
import torch.nn.functional as F
import cv2
import numpy as np


class MaskSplit:
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "mask": ("MASK",),

            },
        }
    
    RETURN_TYPES = ("IMAGE","MASK")
    RETURN_NAMES = ("segmented_images","segmented_masks")
    FUNCTION = "segment_mask"
    
    CATEGORY = "CyberEveLoopğŸ°"

    def find_top_left_point(self, mask_np):
        """æ‰¾åˆ°maskä¸­æœ€å·¦ä¸Šè§’çš„ç‚¹"""
        # æ‰¾åˆ°æ‰€æœ‰éé›¶ç‚¹
        y_coords, x_coords = np.nonzero(mask_np)
        if len(x_coords) == 0:
            return float('inf'), float('inf')
        
        # æ‰¾åˆ°æœ€å°xå€¼
        min_x = np.min(x_coords)
        # åœ¨æœ€å°xå€¼çš„ç‚¹ä¸­æ‰¾åˆ°æœ€å°yå€¼
        min_y = np.min(y_coords[x_coords == min_x])
        
        return min_x, min_y

    def segment_mask(self, mask, image):
        """ä½¿ç”¨OpenCVå¿«é€Ÿåˆ†å‰²è’™ç‰ˆå¹¶å¤„ç†å›¾åƒ"""
        # ä¿å­˜åŸå§‹è®¾å¤‡ä¿¡æ¯
        device = mask.device if isinstance(mask, torch.Tensor) else torch.device('cpu')
        
        # ç¡®ä¿maskæ˜¯æ­£ç¡®çš„å½¢çŠ¶å¹¶è½¬æ¢ä¸ºnumpyæ•°ç»„
        if isinstance(mask, torch.Tensor):
            if len(mask.shape) == 2:
                mask = mask.unsqueeze(0)
            mask_np = (mask[0] * 255).cpu().numpy().astype(np.uint8)
        else:
            mask_np = (mask * 255).astype(np.uint8)
        
        # ä½¿ç”¨OpenCVæ‰¾åˆ°è½®å»“
        contours, hierarchy = cv2.findContours(
            mask_np, 
            cv2.RETR_TREE,
            cv2.CHAIN_APPROX_SIMPLE
        )
        
        mask_info = []  # ç”¨äºæ’åºçš„ä¿¡æ¯åˆ—è¡¨
        
        if hierarchy is not None and len(contours) > 0:
            hierarchy = hierarchy[0]
            contour_masks = {}
            
            # åˆ›å»ºæ¯ä¸ªè½®å»“çš„mask
            for i, contour in enumerate(contours):
                mask = np.zeros_like(mask_np)
                cv2.drawContours(mask, [contour], -1, 255, -1)
                contour_masks[i] = mask

            # å¤„ç†æ¯ä¸ªè½®å»“
            processed_indices = set()
            
            for i, (contour, h) in enumerate(zip(contours, hierarchy)):
                if i in processed_indices:
                    continue
                    
                current_mask = contour_masks[i].copy()
                child_idx = h[2]
                
                if child_idx != -1:
                    while child_idx != -1:
                        current_mask = cv2.subtract(current_mask, contour_masks[child_idx])
                        processed_indices.add(child_idx)
                        child_idx = hierarchy[child_idx][0]
                
                # æ‰¾åˆ°æœ€å·¦ä¸Šè§’çš„ç‚¹
                min_x, min_y = self.find_top_left_point(current_mask)
                
                # è½¬æ¢ä¸ºtensor
                mask_tensor = torch.from_numpy(current_mask).float() / 255.0
                mask_tensor = mask_tensor.unsqueeze(0)
                mask_tensor = mask_tensor.to(device)
                
                # ä¿å­˜maskå’Œæ’åºä¿¡æ¯
                mask_info.append((mask_tensor, min_x, min_y))
                processed_indices.add(i)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•è½®å»“ï¼Œä½¿ç”¨åŸå§‹mask
        if not mask_info:
            if isinstance(mask, torch.Tensor):
                mask_info.append((mask, 0, 0))
            else:
                mask_tensor = torch.from_numpy(mask).float()
                if len(mask_tensor.shape) == 2:
                    mask_tensor = mask_tensor.unsqueeze(0)
                mask_tensor = mask_tensor.to(device)
                mask_info.append((mask_tensor, 0, 0))
        
        # æ ¹æ®æœ€å·¦ä¸Šè§’ç‚¹æ’åº
        mask_info.sort(key=lambda x: (x[1], x[2]))
        
        # ç¡®ä¿imageæ˜¯æ­£ç¡®çš„å½¢çŠ¶
        if len(image.shape) == 3:
            image = image.unsqueeze(0)
        
        # å¤„ç†maskså’Œimages
        result_masks = None
        result_images = None
        
        for mask_tensor, _, _ in mask_info:
            # å¤„ç†masks
            if result_masks is None:
                result_masks = mask_tensor
            else:
                result_masks = torch.cat([result_masks, mask_tensor], dim=0)
            
            # å¤„ç†images
            if result_images is None:
                result_images = image.clone()
            else:
                result_images = torch.cat([result_images, image.clone()], dim=0)
        
        return (result_images, result_masks)



class MaskMerge:
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "original_image": ("IMAGE",),
            },
            "optional": {
                "processed_images": ("IMAGE", {"forceInput": True}),
                "masks": ("MASK", {"forceInput": True}),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("merged_image",)
    FUNCTION = "merge_masked_images"
    CATEGORY = "CyberEveLoopğŸ°"

    def standardize_input(self, image, processed_images=None, masks=None):
        """
        æ ‡å‡†åŒ–è¾“å…¥æ ¼å¼
        - image: [H,W,C] -> [1,H,W,C]
        - processed_images: [...] -> [B,H,W,C]
        - masks: [...] -> [B,H,W]
        """
        # å¤„ç†åŸå§‹å›¾åƒ
        if len(image.shape) == 3:
            image = image.unsqueeze(0)
        assert len(image.shape) == 4, f"Original image must be 4D [B,H,W,C], got shape {image.shape}"

        # å¤„ç†processed_images
        if processed_images is not None:
            if isinstance(processed_images, list):
                processed_images = torch.cat(processed_images, dim=0)
            if len(processed_images.shape) == 3:
                processed_images = processed_images.unsqueeze(0)
            assert len(processed_images.shape) == 4, \
                f"Processed images must be 4D [B,H,W,C], got shape {processed_images.shape}"

        # å¤„ç†masks
        if masks is not None:
            if isinstance(masks, list):
                masks = torch.cat(masks, dim=0)
            if len(masks.shape) == 2:
                masks = masks.unsqueeze(0)
            assert len(masks.shape) == 3, f"Masks must be 3D [B,H,W], got shape {masks.shape}"

        return image, processed_images, masks

    def resize_tensor(self, x, size, mode='bilinear'):
        """è°ƒæ•´tensorå°ºå¯¸çš„è¾…åŠ©å‡½æ•°"""
        # ç¡®ä¿è¾“å…¥æ˜¯4D tensor [B,C,H,W]
        orig_dim = x.dim()
        if orig_dim == 3:
            x = x.unsqueeze(0)
        
        # å¦‚æœæ˜¯å›¾åƒ [B,H,W,C]ï¼Œéœ€è¦è½¬æ¢ä¸º [B,C,H,W]
        if x.shape[-1] in [1, 3, 4]:
            x = x.permute(0, 3, 1, 2)
        
        # æ‰§è¡Œè°ƒæ•´
        x = F.interpolate(x, size=size, mode=mode, align_corners=False if mode in ['bilinear', 'bicubic'] else None)
        
        # è½¬æ¢å›åŸå§‹æ ¼å¼
        if x.shape[1] in [1, 3, 4]:
            x = x.permute(0, 2, 3, 1)
        
        # å¦‚æœåŸå§‹è¾“å…¥æ˜¯3Dï¼Œå»æ‰batchç»´åº¦
        if orig_dim == 3:
            x = x.squeeze(0)
            
        return x

    def merge_masked_images(self, original_image, processed_images=None, masks=None):
        """åˆå¹¶å¤„ç†åçš„å›¾åƒ"""
        # ç¡®ä¿è¾“å…¥æœ‰æ•ˆ
        if processed_images is None or masks is None:
            return (original_image,)
        
        # æ ‡å‡†åŒ–è¾“å…¥
        original_image, processed_images, masks = self.standardize_input(
            original_image, processed_images, masks
        )
        
        # åˆ›å»ºç»“æœå›¾åƒçš„å‰¯æœ¬
        result = original_image.clone()
        
        # è·å–ç›®æ ‡å°ºå¯¸
        target_height = original_image.shape[1]
        target_width = original_image.shape[2]
        
        # è°ƒæ•´å¤„ç†å›¾åƒçš„å°ºå¯¸ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if processed_images.shape[1:3] != (target_height, target_width):
            processed_images = self.resize_tensor(
                processed_images,
                (target_height, target_width),
                mode='bilinear'
            )
        
        # è°ƒæ•´è’™ç‰ˆå°ºå¯¸ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if masks.shape[1:3] != (target_height, target_width):
            masks = self.resize_tensor(
                masks,
                (target_height, target_width),
                mode='bilinear'
            )
        
        # æ‰©å±•è’™ç‰ˆç»´åº¦ä»¥åŒ¹é…å›¾åƒé€šé“
        masks = masks.unsqueeze(-1).expand(-1, -1, -1, 3)
        
        # æ‰¹é‡å¤„ç†æ‰€æœ‰å›¾ç‰‡
        for i in range(processed_images.shape[0]):
            current_image = processed_images[i:i+1]
            current_mask = masks[i:i+1]
            result = current_mask * current_image + (1 - current_mask) * result
        
        assert len(result.shape) == 4, "Output must be 4D [B,H,W,C]"
        return (result,)
    

Mask_CLASS_MAPPINGS = {
    "CyberEve_MaskSegmentation": MaskSplit,
    "CyberEve_MaskMerge": MaskMerge,
}

Mask_DISPLAY_NAME_MAPPINGS = {
    "CyberEve_MaskSegmentation": "Mask SegmentationğŸ°",
    "CyberEve_MaskMerge": "Mask MergeğŸ°",
}

